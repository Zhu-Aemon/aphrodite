{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "import shutup\n",
    "import pandas as pd\n",
    "\n",
    "shutup.please()\n",
    "\n",
    "# sina_futures = ak.futures_display_main_sina()\n",
    "# sina_futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CN_commodity import get_latest_date_cn, cn_daily_update\n",
    "\n",
    "# get_latest_date_cn(symbol='A0').date()\n",
    "test = cn_daily_update(symbol='V0')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71fdea655c575b8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d02aba56de6d3fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['date'] = pd.to_datetime(test['date']).dt.date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd3aaa12a0f0e474"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test[test['date'] > get_latest_date_cn(symbol='V0')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c6321216b7cbe2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['date'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "624b5d0f6a34e51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_latest_date_cn(symbol='V0')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df782306dbd08b66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.to_datetime(test['date']).dt.date[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b6dc7c43907632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "datetime.datetime.now().date()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62a27ec8f11de13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PVC_data = ak.futures_main_sina(symbol='AG0')\n",
    "PVC_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4164402eb6ccea33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PVC_data.rename(columns={'日期': 'date', '开盘价': 'open', '收盘价': 'close', '最高价': 'high', '最低价': 'low', '成交量': 'volume', '持仓量': 'inventory'}, inplace=True)\n",
    "PVC_data.drop(columns=['动态结算价'], inplace=True)\n",
    "PVC_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d90aee23fd47a860"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sina_futures.sort_values(by='symbol')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea90f7cae65ff607"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import threading\n",
    "import sys\n",
    "\n",
    "\n",
    "class FOMC(object):\n",
    "    \"\"\"\n",
    "    A convenient class for extracting meeting minutes from the FOMC website\n",
    "    Example Usage:\n",
    "        fomc = FOMC()\n",
    "        df = fomc.get_statements()\n",
    "        fomc.pickle(\"./df_minutes.pickle\")\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_url='https://www.federalreserve.gov',\n",
    "                 calendar_url='https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm',\n",
    "                 historical_date=2011,\n",
    "                 verbose=True,\n",
    "                 max_threads=10):\n",
    "\n",
    "        self.base_url = base_url\n",
    "        self.calendar_url = calendar_url\n",
    "        self.df = None\n",
    "        self.links = None\n",
    "        self.dates = None\n",
    "        self.articles = None\n",
    "        self.verbose = verbose\n",
    "        self.HISTORICAL_DATE = historical_date\n",
    "        self.MAX_THREADS = max_threads\n",
    "\n",
    "    def _get_links(self, from_year):\n",
    "        \"\"\"\n",
    "        private function that sets all the links for the FOMC meetings from the giving from_year\n",
    "        to the current most recent year\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Getting links...\")\n",
    "        self.links = []\n",
    "        fomc_meetings_socket = urlopen(self.calendar_url)\n",
    "        soup = BeautifulSoup(fomc_meetings_socket, 'html.parser')\n",
    "\n",
    "        statements = soup.find_all('a', href=re.compile('^/newsevents/pressreleases/monetary\\d{8}a.htm'))\n",
    "        self.links = [statement.attrs['href'] for statement in statements]\n",
    "\n",
    "        if from_year <= self.HISTORICAL_DATE:\n",
    "            for year in range(from_year, self.HISTORICAL_DATE + 1):\n",
    "                fomc_yearly_url = self.base_url + '/monetarypolicy/fomchistorical' + str(year) + '.htm'\n",
    "                fomc_yearly_socket = urlopen(fomc_yearly_url)\n",
    "                soup_yearly = BeautifulSoup(fomc_yearly_socket, 'html.parser')\n",
    "                statements_historical = soup_yearly.findAll('a', text='Statement')\n",
    "                for statement_historical in statements_historical:\n",
    "                    self.links.append(statement_historical.attrs['href'])\n",
    "\n",
    "    def _date_from_link(self, link):\n",
    "        date = re.findall('[0-9]{8}', link)[0]\n",
    "        if date[4] == '0':\n",
    "            date = \"{}/{}/{}\".format(date[:4], date[5:6], date[6:])\n",
    "        else:\n",
    "            date = \"{}/{}/{}\".format(date[:4], date[4:6], date[6:])\n",
    "        return date\n",
    "\n",
    "    def _add_article(self, link, index=None):\n",
    "        \"\"\"\n",
    "        adds the related article for 1 link into the instance variable\n",
    "        index is the index in the article to add to. Due to concurrent\n",
    "        processing, we need to make sure the articles are stored in the\n",
    "        right order\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # date of the article content\n",
    "        self.dates.append(self._date_from_link(link))\n",
    "        statement_socket = urlopen(self.base_url + link)\n",
    "        statement = BeautifulSoup(statement_socket, 'html.parser')\n",
    "        paragraphs = statement.findAll('p')\n",
    "        self.articles[index] = \"\\n\\n\".join([paragraph.get_text().strip() for paragraph in paragraphs])\n",
    "\n",
    "    def _get_articles_multi_threaded(self):\n",
    "        \"\"\"\n",
    "        gets all articles using multi-threading\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Getting articles - Multi-threaded...\")\n",
    "\n",
    "        self.dates, self.articles = [], [''] * len(self.links)\n",
    "        jobs = []\n",
    "        # initiate and start threads:\n",
    "        index = 0\n",
    "        while index < len(self.links):\n",
    "            if len(jobs) < self.MAX_THREADS:\n",
    "                t = threading.Thread(target=self._add_article, args=(self.links[index], index,))\n",
    "                jobs.append(t)\n",
    "                t.start()\n",
    "                index += 1\n",
    "            else:  # wait for threads to complete and join them back into the main thread\n",
    "                t = jobs.pop(0)\n",
    "                t.join()\n",
    "        for t in jobs:\n",
    "            t.join()\n",
    "\n",
    "        for row in range(len(self.articles)):\n",
    "            self.articles[row] = self.articles[row].strip()\n",
    "\n",
    "    def get_statements(self, from_year=1994):\n",
    "        \"\"\"\n",
    "        Returns a Pandas DataFrame of meeting minutes with the date as the index\n",
    "        uses a date range of from_year to the most current\n",
    "\n",
    "        Input from_year is ignored if it is within the last 5 years as this is meant for\n",
    "        parsing much older years\n",
    "        \"\"\"\n",
    "        self._get_links(from_year)\n",
    "        print(\"There are\", len(self.links), 'statements')\n",
    "        self._get_articles_multi_threaded()\n",
    "\n",
    "        self.df = pd.DataFrame(self.articles, index=pd.to_datetime(self.dates)).sort_index()\n",
    "        self.df.columns = ['statements']\n",
    "        return self.df\n",
    "\n",
    "    def pick_df(self, filename=\"../data/minutes.pickle\"):\n",
    "        if filename:\n",
    "            if self.verbose:\n",
    "                print(\"Writing to\", filename)\n",
    "            with open(filename, \"wb\") as output_file:\n",
    "                pickle.dump(self.df, output_file)\n",
    "\n",
    "# Example Usage\n",
    "fomc = FOMC()\n",
    "df = fomc.get_statements()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3f1384a898447c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a624ff251fb2546"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
